# Polymarket Data Downloader & Processor

This project contains Python scripts to download historical market and event data from the Polymarket Gamma API and process it into a usable TSV format.

## Scripts

1.  **`download_markets.py`**: Fetches market data in batches based on status (e.g., closed) and saves each batch as a `.jsonl` file in the specified output directory.

    *   **Purpose**: Downloads the initial set of market overview data.
    *   **Output Directory**: Contains files like `markets_offset_0_limit_20.jsonl`.
    *   **Resume**: Automatically detects the last successfully saved batch and resumes downloading from the next offset.
    *   **Example Command**:
        ```bash
        python download_markets.py --output-dir market_data --status closed
        ```

2.  **`download_event_details.py`**: Scans the market `.jsonl` files generated by the first script, extracts all unique event IDs mentioned, and then fetches the full details for each event ID using the `/events/{id}` endpoint. Saves each event's details into a separate JSON file.

    *   **Purpose**: Downloads detailed data for every event associated with the downloaded markets.
    *   **Input Directory**: The directory containing the market `.jsonl` files (e.g., `market_data`).
    *   **Output Directory**: Contains files like `event_12345.json`.
    *   **Resume**: Checks for existing event files and only downloads details for events not already present.
    *   **Parallelism**: Uses multiple workers (default 8) to speed up downloads.
    *   **Example Command**:
        ```bash
        python download_event_details.py --market-data-dir market_data --output-dir event_details --workers 10
        ```

3.  **`process_data.py`**: Processes the downloaded market and event data.

    *   **Task 1 (Optional)**: Saves each market from the `.jsonl` files into an individual `market_{id}.json` file for easier access.
    *   **Task 2 (Optional)**: Reads the market `.jsonl` files and the corresponding event detail JSONs, joins the data (based on the first event listed in the market), and creates a single, comprehensive TSV file containing columns from both sources (prefixed with `market_` and `event_`).
    *   **Inputs**: Market data directory, event details directory.
    *   **Outputs**: Individual market JSON directory (for Task 1), final TSV file (for Task 2).
    *   **Example Command (Both Tasks)**:
        ```bash
        python process_data.py \
            --market-data-dir market_data \
            --event-details-dir event_details \
            --market-output-dir market_details \
            --tsv-output-file polymarket_data.tsv
        ```
    *   **Example Command (Only Task 2 - TSV Creation)**:
        ```bash
        python process_data.py \
            --market-data-dir market_data \
            --event-details-dir event_details \
            --tsv-output-file polymarket_data.tsv \
            --skip-task1
        ```

## Data Flow

1.  Run `download_markets.py` to get market overviews (`market_data/`).
2.  Run `download_event_details.py` to get event details (`event_details/`).
3.  Run `process_data.py`:
    *   (Optional) Creates individual market JSONs (`market_details/`).
    *   Creates the final joined TSV (`polymarket_data.tsv`).

## Requirements

*   Python 3.x
*   `requests` library (`pip install requests`)
